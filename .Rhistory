imposter <- as.data.frame(result$imposter)
genuine <- as.data.frame(result$genuine)
#Scale using the density function and plot using ggplot's geom_freqpoly.
plot <- ggplot() + geom_freqpoly(data = imposter, aes(x = imposter, y = ..density..), bins = 50, color = "red") + geom_freqpoly(data = genuine, aes(x = genuine, y = ..density..), bins = 50) + labs(title = "Distribution of Scores") + labs(x = "Match Score", y = "Scaled Frequency") + scale_color_manual(values = c(imposter = "imposter", genuine = "genuine"))
print(plot)
}
plot.DET <- function(result){
imposter <- as.data.frame(result$imposter)
genuine <- as.data.frame(result$genuine)
FAR_vs_FRR <- NULL
#For each value of t, calculate FAR and FRR and add to dataset.
for (t in seq(from = 0, to = 120.0, by = 2)){
false_accept_count <- sum(imposter < t)
false_accept_rate <- false_accept_count/dim(imposter)[1]
false_reject_count <- sum(genuine > t)
false_reject_rate <- false_reject_count/dim(genuine)[1]
current_row <- c(false_accept_rate, false_reject_rate)
FAR_vs_FRR<- rbind(FAR_vs_FRR, current_row)
}
rates_data_frame <- as.data.frame(FAR_vs_FRR)
colnames(rates_data_frame) <- c("FAR", "FRR")
plot <- ggplot(rates_data_frame, aes(x=FAR, y = FRR)) + geom_point() + geom_abline(slope = 1, intercept = 0) + labs(title = "DET curve")
print(plot)
return(rates_data_frame)
}
get.EER <- function(rates_data_frame){
#Make new column containing boolean FAR > FRR.
rates_data_frame$larger <- rates_data_frame$FAR > rates_data_frame$FRR
#Find where FAR becomes less than FRR. Use these as upper and lower boundaries to estimate the EER.
far_is_smaller <- rates_data_frame[rates_data_frame$larger=="FALSE", ]
lower_bound <- max(far_is_smaller$FAR)
far_is_larger <- rates_data_frame[rates_data_frame$larger=="TRUE", ]
upper_bound <- min(far_is_larger$FAR)
EER <- mean(lower_bound, upper_bound)
print(EER)
}
plot.scores(result)
rates_data_frame <- plot.DET(result)
get.EER(rates_data_frame)
plot.scores <- function(result){
imposter <- as.data.frame(result$imposter)
genuine <- as.data.frame(result$genuine)
#Scale using the density function and plot using ggplot's geom_freqpoly.
plot <- ggplot() +
geom_freqpoly(data = imposter, aes(x = imposter, y = ..density..), bins = 50, color = "red") +
geom_freqpoly(data = genuine, aes(x = genuine, y = ..density..), bins = 50) +
labs(title = "Distribution of Scores") +
labs(x = "Match Score", y = "Scaled Frequency")
print(plot)
}
plot.DET <- function(result){
imposter <- as.data.frame(result$imposter)
genuine <- as.data.frame(result$genuine)
FAR_vs_FRR <- NULL
#For each value of t, calculate FAR and FRR and add to dataset.
for (t in seq(from = 0, to = 120.0, by = 2)){
false_accept_count <- sum(imposter < t)
false_accept_rate <- false_accept_count/dim(imposter)[1]
false_reject_count <- sum(genuine > t)
false_reject_rate <- false_reject_count/dim(genuine)[1]
current_row <- c(false_accept_rate, false_reject_rate)
FAR_vs_FRR<- rbind(FAR_vs_FRR, current_row)
}
rates_data_frame <- as.data.frame(FAR_vs_FRR)
colnames(rates_data_frame) <- c("FAR", "FRR")
plot <- ggplot(rates_data_frame, aes(x=FAR, y = FRR)) + geom_point() + geom_abline(slope = 1, intercept = 0) + labs(title = "DET curve")
print(plot)
return(rates_data_frame)
}
get.EER <- function(rates_data_frame){
#Make new column containing boolean FAR > FRR.
rates_data_frame$larger <- rates_data_frame$FAR > rates_data_frame$FRR
#Find where FAR becomes less than FRR. Use these as upper and lower boundaries to estimate the EER.
far_is_smaller <- rates_data_frame[rates_data_frame$larger=="FALSE", ]
lower_bound <- max(far_is_smaller$FAR)
far_is_larger <- rates_data_frame[rates_data_frame$larger=="TRUE", ]
upper_bound <- min(far_is_larger$FAR)
EER <- mean(lower_bound, upper_bound)
print(EER)
}
plot.scores(result)
rates_data_frame <- plot.DET(result)
get.EER(rates_data_frame)
directory = "/Users/jen/Dropbox/CSCI 454/hw/trainingfaces2"
filenames <- list.files(path = directory)
training <- read.files(filenames, directory)
MMScale <- function(dataset){
col.mins <- apply(dataset, 2, min)
intermediate.result <- t(t(dataset)-col.mins)
col.maxes <- apply(dataset, 2, max)
denominator <- col.maxes - col.mins
dataset <- t(t(intermediate.result)/denominator)
return(dataset)
}
training <- MMScale(training)
X <- center.data(training)
trans.EV <- calculate.eigens(X, 30)
directory = "/Users/jen/Dropbox/CSCI 454/hw/testingfaces2"
filenames <- list.files(path = directory)
testing <- read.files(filenames, directory)
testing <- MMScale(testing)
testing <- testing - training[ ,dim(training)[2]]
weight.matrices <- make.weight.matrix(trans.EV, testing)
result <- make.gen.imposter(weight.matrices)
plot.scores(result)
rates_data_frame <- plot.DET(result)
get.EER(rates_data_frame)
directory = "/Users/jen/Dropbox/CSCI 454/hw/trainingfaces2"
filenames <- list.files(path = directory)
training <- read.files(filenames, directory)
training <- MMScale(training)
X <- center.data(training)
trans.EV <- calculate.eigens(X, 30)
directory = "/Users/jen/Dropbox/CSCI 454/hw/testingaligned2"
filenames <- list.files(path = directory)
testing <- read.files(filenames, directory)
testing <- MMScale(testing)
testing <- testing - training[ ,dim(training)[2]]
weight.matrices <- make.weight.matrix(trans.EV, testing)
result <- make.gen.imposter(weight.matrices)
plot.scores(result)
rates_data_frame <- plot.DET(result)
get.EER(rates_data_frame)
directory = "/Users/jen/Dropbox/CSCI 454/hw/trainingfaces2"
filenames <- list.files(path = directory)
training <- read.files(filenames, directory)
x.and.y.to.list.index <- function(x, y){
if (x == 0) {
if (y == 0) {
final.index = 1
} else if (y == 1) {
final.index = 2
} else {
final.index = 3
}
} else if (x == 1){
if (y == 0) {
final.index = 4
} else if (y == 1) {
final.index = 5
} else {
final.index = 6
}
} else {
if (y == 0) {
final.index = 7
} else if (y == 1) {
final.index = 8
} else {
final.index = 9
}
}
return(final.index)
}
directory <- "/Users/jen/Dropbox/CSCI 454/hw/trainingfaces2"
filenames <- list.files(path = directory)
x.and.y.to.list.index <- function(x, y){
if (x == 0) {
if (y == 0) {
final.index = 1
} else if (y == 1) {
final.index = 2
} else {
final.index = 3
}
} else if (x == 1){
if (y == 0) {
final.index = 4
} else if (y == 1) {
final.index = 5
} else {
final.index = 6
}
} else {
if (y == 0) {
final.index = 7
} else if (y == 1) {
final.index = 8
} else {
final.index = 9
}
}
return(final.index)
}
read.divide.files <- function(directory, filenames){
dim.img <- 60
one.third <- dim.img[1]/3
len.array <- one.third ** 2
sectors <- array(NA, c(len.array, length(filenames), 9))
for (f in 1:length(filenames)) {
img <- readPNG(paste(directory, filenames[f], sep = "/"))
for (i in 0:2){
min1 <- i*one.third +1
max1 <- min1 + one.third - 1
for (j in 0:2){
min2 <- j * one.third + 1
max2 <- min2 + one.third - 1
current <- img[min1:max1, min2:max2]
to.add <- as.vector(current)
# get index from x and y using helper function
index <- x.and.y.to.list.index(i, j)
# assign using indices
sectors[,f,index] <- to.add
}
}
}
return(sectors)
}
sectors <- read.divide.files(directory, filenames)
dim(sectors)
weights <- array(NA, c(20, len.array, 9))
dim.img <- 60
one.third <- dim.img[1]/3
len.array <- one.third ** 2
read.divide.files <- function(directory, filenames){
sectors <- array(NA, c(len.array, length(filenames), 9))
for (f in 1:length(filenames)) {
img <- readPNG(paste(directory, filenames[f], sep = "/"))
for (i in 0:2){
min1 <- i*one.third +1
max1 <- min1 + one.third - 1
for (j in 0:2){
min2 <- j * one.third + 1
max2 <- min2 + one.third - 1
current <- img[min1:max1, min2:max2]
to.add <- as.vector(current)
# get index from x and y using helper function
index <- x.and.y.to.list.index(i, j)
# assign using indices
sectors[,f,index] <- to.add
}
}
}
return(sectors)
}
sectors <- read.divide.files(directory, filenames)
weights <- array(NA, c(20, len.array, 9))
mean.rows.per.sector <- array(NA, c(len.array, 1 ,9))
for (i in 1:dim(sectors)[3]){
training <- sectors[,,i]
training <- MMScale(training)
# Centering
mean.rows <- apply(training, 1, mean)
training <- cbind(training, mean.rows)
mean.rows.per.sector[,,i] <- mean.rows
X <- training[ , 1:dim(training)[2]-1]-training[ ,dim(training)[2]]
trans.EV <- calculate.eigens(X, 20)
weights[,,i] <- trans.EV
}
directory <- "/Users/jen/Dropbox/CSCI 454/hw/testingfaces2"
filenames <- list.files(path = directory)
sectors <- read.divide.files(directory, filenames)
for (i in 1:dim(sectors)[3]){
testing <- sectors[,,i]
testing <- MMScale(testing)
# Subtract the mean of the training data for that sector
sectors[,,i] <- testing - mean.rows.per.sector[,,i]
}
weights.x.images <- array(NA, c(20, length(filenames), 9))
for (i in 1:dim(sectors)[3]){
current.img <- sectors[,,i]
current.weights <- weights[,,i]
weights.x.images[,,i] <- current.weights %*% current.img
}
true.matches.false.imposters <- c()
for (i in 1:length(filenames)){
j <- i+1
while (j <= length(filenames)){
image1 <- filenames[i]
subject1 <- substr(image1, 2, 3)
image2 <- filenames[j]
subject2 <- substr(image2, 2, 3)
if (subject1 == subject2) {
true.matches.false.imposters <- c(true.matches.false.imposters, TRUE)
} else {
true.matches.false.imposters <- c(true.matches.false.imposters, FALSE)
}
j <- j+1
}
}
distance.scores.to.be.weighted <- c()
for (d in 1:dim(sectors)[3]){
current.col.to.add <- c()
current <- weights.x.images[,,d]
for (i in 1:length(filenames)){
j <- i+1
while (j <= length(filenames)){
weight1 <- current[, i]
weight2 <- current[, j]
weight.diff <- sum(abs(weight1-weight2))
current.col.to.add <- c(current.col.to.add, weight.diff)
j <- j+1
}
}
distance.scores.to.be.weighted <- cbind(distance.scores.to.be.weighted, current.col.to.add)
print(d)
}
weights <- c(1, 2, 1, 2, 2, 2, 1, 2, 1)
weighted.scores <- t(t(distance.scores.to.be.weighted) * weights)
total.score <- apply(weighted.scores, 1, sum)
scores <- data.frame(cbind(true.matches.false.imposters, total.score))
genuine <- scores %>% filter(true.matches.false.imposters == 1) %>% select(total.score)
imposter <- scores %>% filter(true.matches.false.imposters == 0) %>% select(total.score)
theme_update(plot.title = element_text(hjust = 0.5))
imposter <- as.data.frame(imposter)
genuine <- as.data.frame(genuine)
#Scale using the density function and plot using ggplot's geom_freqpoly.
ggplot() + geom_freqpoly(data = imposter, aes(x = total.score, y = ..density..), bins = 50, color = "red") + geom_freqpoly(data = genuine, aes(x = total.score, y = ..density..), bins = 50) + labs(title = "Distribution of Scores") + labs(x = "Match Score", y = "Scaled Frequency")
FAR_vs_FRR <- NULL
for (t in seq(from = 100, to = 400, by = 10)){
false_accept_count <- sum(imposter < t)
false_accept_rate <- false_accept_count/dim(imposter)[1]
false_reject_count <- sum(genuine > t)
false_reject_rate <- false_reject_count/dim(genuine)[1]
current_row <- c(false_accept_rate, false_reject_rate)
FAR_vs_FRR<- rbind(FAR_vs_FRR, current_row)
}
rates_data_frame <- as.data.frame(FAR_vs_FRR)
colnames(rates_data_frame) <- c("FAR", "FRR")
ggplot(rates_data_frame, aes(x=FAR, y = FRR)) + geom_point() + geom_abline(slope = 1, intercept = 0) + labs(title = "DET curve")
rates_data_frame$larger <- rates_data_frame$FAR > rates_data_frame$FRR
far_is_smaller <- rates_data_frame[rates_data_frame$larger=="FALSE", ]
lower_bound <- max(far_is_smaller$FAR)
far_is_larger <- rates_data_frame[rates_data_frame$larger=="TRUE", ]
upper_bound <- min(far_is_larger$FAR)
EER <- mean(lower_bound, upper_bound)
print(EER)
shiny::runApp('Dropbox/MATH 216/final_project/math216_diseases')
library(miniCharts)
library(leaflet.miniCharts)
shiny::runApp('Dropbox/MATH 216/final_project/math216_diseases')
runApp('Dropbox/MATH 216/final_project/math216_diseases')
shiny::runApp('Dropbox/Reference/MATH 216/final_project/math216_diseases')
runApp('Dropbox/Reference/MATH 216/final_project/math216_diseases')
install.packages("VariantAnnotation")
install.packages("VariantAnnotation")
source("https://bioconductor.org/biocLite.R")
biocLite("VariantAnnotation")
library(VariantAnnotation)
warnings()
fl <- system.file("extdata", "chr7-sub.vcf.gz", package = "VariantAnnotation")
fl
vcf1 <- readVcf(fl, "hg19")
View(vcf1)
vcf1
which <- GRanges("7", IRanges(55000723, width = 1000))
param <- ScanVcfParam(which=which)
which
param
vcf2 <- readVcf(fl, "hg19", param = param)
vcf2
dim(vcf2)
param <-ScanVcfParam(info="SS", geno = "GT")
vcf3 <- readVCF(fl, "hg19", param = param)
vcf3 <- readVCF(fl, "hg19", param = param)
vcf3 <- readVcF(fl, "hg19", param = param)
vcf3 <- readVcf(fl, "hg19", param = param)
vcf3
ft <- readGeno(fl, "FT", row.names = FALSE)
class(ft)
dim(ft)
apply(ft, 2, table)
vranges <- readVcfAsVRanges(fl, "hg19", use.names = TRUE)
head(vranges, 4)
help(VariantAnnotation)
??`VariantAnnotation-defunct`
help(system.file)
help("readVcf")
?TabixFile
?write.table
source('~/Desktop/citation-categories/assess_performance.R')
?stop
setwd("~/Desktop/classifier_with_sum_rule")
library(tidyverse)
training <- read.csv('input_data/synthetic_training.csv', header = TRUE, stringsAsFactors = FALSE)
testing <- read.csv('input_data/synthetic_testing.csv', header = TRUE, stringsAsFactors = FALSE)
View(testing)
View(training)
training <- read.csv('input_data/synthetic_training.csv', header = TRUE, stringsAsFactors = FALSE)
testing <- read.csv('input_data/synthetic_testing.csv', header = TRUE, stringsAsFactors = FALSE)
total_data <- rbind(training, testing)
truths_to_write <- total_data %>% select(AlleleID.s., Clinsig)
truths_to_write$ones <- rep(1.0, nrow(total_data))
write.table(truths_to_write, "psl_data/path_truths.txt", row.names = FALSE, col.names = FALSE, sep = "\t")
obs_to_write <- training %>% select(AlleleID.s., Clinsig)
obs_to_write$ones <- rep(1.0, nrow(training))
write.table(obs_to_write, "psl_data/path_obs.txt", row.names = FALSE, col.names = FALSE, sep = "\t")
write.table(truths_to_write, "psl_data/path_truths.txt", row.names = FALSE, col.names = FALSE, sep = "\t")
obs_to_write <- training %>% select(AlleleID.s., Clinsig)
obs_to_write$ones <- rep(1.0, nrow(training))
write.table(obs_to_write, "psl_data/path_obs.txt", row.names = FALSE, col.names = FALSE, sep = "\t")
min_max_scale <- function(df){
# df is id, clinsig, an
max_an <- max(df$an)
min_an <- min(df$an)
denom = max_an-min_an
df$truth_value <- (df$an - min_an)/denom
df <- df %>% select(AlleleID.s., Clinsig, truth_value)
# should be id, clinsig, truth_value
return(df)
}
an_to_scale <- training %>% select(AlleleID.s., Clinsig, an)
truths_to_write <- min_max_scale(an_to_scale)
View(truths_to_write)
an_to_scale <- total_data %>% select(AlleleID.s., Clinsig, an)
truths_to_write <- min_max_scale(an_to_scale)
View(truths_to_write)
View(truths_to_write)
source('~/Desktop/classifier_with_sum_rule/write_synthetic_obs.R')
truths_to_write[1:]
truths_to_write[1: ]
nrow(training)
head(truths_to_write, nrow(training))
obs_to_write <- head(truths_to_write, nrow(training))
write.table(obs_to_write, "psl_data/path_obs_scaled.txt", row.names = FALSE, col.names = FALSE, sep = "\t")
write.table(truths_to_write, "psl_data/path_truths_scaled.txt", row.names = FALSE, col.names = FALSE, sep = "\t")
classes <- unique(total_data$Clinsig)
targets_to_write <- testing %>% select(AlleleID.s.)
temp <- cbind(targets_to_write, rep(classes[1], nrow(testing)))
temp2 <- cbind(targets_to_write, rep(classes[2], nrow(testing)))
colnames(temp)[2] <- "Class"
colnames(temp2)[2] <- "Class"
targets_to_write <- rbind(temp, temp2)
write.table(targets_to_write, "psl_data/path_targets.txt", row.names = FALSE, col.names = FALSE, sep = "\t")
write_obs <- function(df, result){
df <- unique(df$AlleleID.s.)
max_index <- length(df)
for (i in 1:max_index){
j <- i+1
if (j <= max_index){
for (k in j:max_index){
row <- cbind(df[i], df[k])
result <- rbind(result, row)
}
}
}
return(result)
}
ad_link <- data.frame()
write_AD_AR <- function(value, ad_link){
AR <- total_data %>%
filter(AD_AR == value) %>%
select(AlleleID.s.)
ad_link <- write_obs(AR, ad_link)
return(ad_link)
}
ad_link <- write_AD_AR(0, ad_link)
ad_link <- write_AD_AR(1, ad_link)
an_link <- data.frame()
write_an <- function(threshold){
for (i in 1:2){
if (i == 1){
AN <- total_data %>%
filter(an > threshold)
} else {
AN <- total_data %>%
filter(an < threshold)
}
an_link <- write_obs(AN, an_link)
}
return(an_link)
}
threshold <- 15000
total_data$quality_bool <- total_data$an > threshold
an_link <- write_an(threshold)
af_link <- data.frame()
write_af_cats <- function(quality_value, ad_ar_value, thresholds, af_link){
filtered_data <- total_data %>%
filter(quality_bool == quality_value) %>%
filter(AD_AR == ad_ar_value) %>%
select(AlleleID.s., af)
# partition
cat1 <- filtered_data %>%
filter(af > thresholds[1]) %>%
select(AlleleID.s.)
tempcat1 <- filtered_data %>%
filter(af < thresholds[1])
cat2 <- tempcat1 %>%
filter(af > thresholds[2]) %>%
select(AlleleID.s.)
tempcat2 <- tempcat1 %>%
filter(af < thresholds[2])
if (length(thresholds == 3)){
cat3 <- tempcat2 %>%
filter(af > thresholds[3]) %>%
select(AlleleID.s.)
cat4 <- tempcat2 %>%
filter(af < thresholds[3]) %>%
select(AlleleID.s.)
af_link <- write_obs(cat4, af_link)
} else {
cat3 <- temp_cat2 %>% select(AlleleId.s.)
}
af_link <- write_obs(cat1, af_link)
af_link <- write_obs(cat2, af_link)
af_link <- write_obs(cat3, af_link)
return(af_link)
}
af_link <- write_af_cats("FALSE", 0, c(3, 1, 0.3), af_link)
af_link <- write_af_cats("FALSE", 1, c(1.5, 0.5, 0.1), af_link)
af_link <- write_af_cats("TRUE", 0, c(1, 0.3), af_link)
af_link <- write_af_cats("TRUE", 1, c(0.5, 0.1), af_link)
add_ones <- function(df){
df$ones <- rep(1.0, nrow(df))
return(df)
}
an_link <- add_ones(an_link)
ad_link <- add_ones(ad_link)
af_link <- add_ones(af_link)
write.table(ad_link, "psl_data/HasSimilarAD-Ones.txt", row.names = FALSE, col.names = FALSE, sep = "\t")
write.table(an_link, "psl_data/HasSimilarAN-Ones.txt", row.names = FALSE, col.names = FALSE, sep = "\t")
write.table(af_link, "psl_data/HasSimilarAF-Ones.txt", row.names = FALSE, col.names = FALSE, sep = "\t")
