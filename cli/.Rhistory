image1 <- filenames[i]
subject1 <- substr(image1, 2, 3)
j <- i+1
while (j <= length(filenames)){
image2 <- filenames[j]
subject2 <- substr(image2, 2, 3)
weight1 <- weight.matrices[, i]
weight2 <- weight.matrices[, j]
weight.diff <- sum(abs(weight1-weight2))
current.row <- cbind(image1, image2, weight.diff)
all.data <- rbind(all.data, current.row)
if (subject1 == subject2) {
genuine <- c(genuine, weight.diff)
} else {
imposter <- c(imposter, weight.diff)
}
j <- j+1
}
}
return(list("genuine" = genuine, "imposter" = imposter))
}
result <- make.gen.imposter(weight.matrices)
?gglegend
plot.scores <- function(result){
imposter <- as.data.frame(result$imposter)
genuine <- as.data.frame(result$genuine)
#Scale using the density function and plot using ggplot's geom_freqpoly.
plot <- ggplot() + geom_freqpoly(data = imposter, aes(x = imposter, y = ..density..), bins = 50, color = "red") + geom_freqpoly(data = genuine, aes(x = genuine, y = ..density..), bins = 50) + labs(title = "Distribution of Scores") + labs(x = "Match Score", y = "Scaled Frequency") + scale_color_manual(values = c(imposter = "imposter", genuine = "genuine"))
print(plot)
}
plot.DET <- function(result){
imposter <- as.data.frame(result$imposter)
genuine <- as.data.frame(result$genuine)
FAR_vs_FRR <- NULL
#For each value of t, calculate FAR and FRR and add to dataset.
for (t in seq(from = 0, to = 120.0, by = 2)){
false_accept_count <- sum(imposter < t)
false_accept_rate <- false_accept_count/dim(imposter)[1]
false_reject_count <- sum(genuine > t)
false_reject_rate <- false_reject_count/dim(genuine)[1]
current_row <- c(false_accept_rate, false_reject_rate)
FAR_vs_FRR<- rbind(FAR_vs_FRR, current_row)
}
rates_data_frame <- as.data.frame(FAR_vs_FRR)
colnames(rates_data_frame) <- c("FAR", "FRR")
plot <- ggplot(rates_data_frame, aes(x=FAR, y = FRR)) + geom_point() + geom_abline(slope = 1, intercept = 0) + labs(title = "DET curve")
print(plot)
return(rates_data_frame)
}
get.EER <- function(rates_data_frame){
#Make new column containing boolean FAR > FRR.
rates_data_frame$larger <- rates_data_frame$FAR > rates_data_frame$FRR
#Find where FAR becomes less than FRR. Use these as upper and lower boundaries to estimate the EER.
far_is_smaller <- rates_data_frame[rates_data_frame$larger=="FALSE", ]
lower_bound <- max(far_is_smaller$FAR)
far_is_larger <- rates_data_frame[rates_data_frame$larger=="TRUE", ]
upper_bound <- min(far_is_larger$FAR)
EER <- mean(lower_bound, upper_bound)
print(EER)
}
plot.scores(result)
rates_data_frame <- plot.DET(result)
get.EER(rates_data_frame)
plot.scores <- function(result){
imposter <- as.data.frame(result$imposter)
genuine <- as.data.frame(result$genuine)
#Scale using the density function and plot using ggplot's geom_freqpoly.
plot <- ggplot() +
geom_freqpoly(data = imposter, aes(x = imposter, y = ..density..), bins = 50, color = "red") +
geom_freqpoly(data = genuine, aes(x = genuine, y = ..density..), bins = 50) +
labs(title = "Distribution of Scores") +
labs(x = "Match Score", y = "Scaled Frequency")
print(plot)
}
plot.DET <- function(result){
imposter <- as.data.frame(result$imposter)
genuine <- as.data.frame(result$genuine)
FAR_vs_FRR <- NULL
#For each value of t, calculate FAR and FRR and add to dataset.
for (t in seq(from = 0, to = 120.0, by = 2)){
false_accept_count <- sum(imposter < t)
false_accept_rate <- false_accept_count/dim(imposter)[1]
false_reject_count <- sum(genuine > t)
false_reject_rate <- false_reject_count/dim(genuine)[1]
current_row <- c(false_accept_rate, false_reject_rate)
FAR_vs_FRR<- rbind(FAR_vs_FRR, current_row)
}
rates_data_frame <- as.data.frame(FAR_vs_FRR)
colnames(rates_data_frame) <- c("FAR", "FRR")
plot <- ggplot(rates_data_frame, aes(x=FAR, y = FRR)) + geom_point() + geom_abline(slope = 1, intercept = 0) + labs(title = "DET curve")
print(plot)
return(rates_data_frame)
}
get.EER <- function(rates_data_frame){
#Make new column containing boolean FAR > FRR.
rates_data_frame$larger <- rates_data_frame$FAR > rates_data_frame$FRR
#Find where FAR becomes less than FRR. Use these as upper and lower boundaries to estimate the EER.
far_is_smaller <- rates_data_frame[rates_data_frame$larger=="FALSE", ]
lower_bound <- max(far_is_smaller$FAR)
far_is_larger <- rates_data_frame[rates_data_frame$larger=="TRUE", ]
upper_bound <- min(far_is_larger$FAR)
EER <- mean(lower_bound, upper_bound)
print(EER)
}
plot.scores(result)
rates_data_frame <- plot.DET(result)
get.EER(rates_data_frame)
directory = "/Users/jen/Dropbox/CSCI 454/hw/trainingfaces2"
filenames <- list.files(path = directory)
training <- read.files(filenames, directory)
MMScale <- function(dataset){
col.mins <- apply(dataset, 2, min)
intermediate.result <- t(t(dataset)-col.mins)
col.maxes <- apply(dataset, 2, max)
denominator <- col.maxes - col.mins
dataset <- t(t(intermediate.result)/denominator)
return(dataset)
}
training <- MMScale(training)
X <- center.data(training)
trans.EV <- calculate.eigens(X, 30)
directory = "/Users/jen/Dropbox/CSCI 454/hw/testingfaces2"
filenames <- list.files(path = directory)
testing <- read.files(filenames, directory)
testing <- MMScale(testing)
testing <- testing - training[ ,dim(training)[2]]
weight.matrices <- make.weight.matrix(trans.EV, testing)
result <- make.gen.imposter(weight.matrices)
plot.scores(result)
rates_data_frame <- plot.DET(result)
get.EER(rates_data_frame)
directory = "/Users/jen/Dropbox/CSCI 454/hw/trainingfaces2"
filenames <- list.files(path = directory)
training <- read.files(filenames, directory)
training <- MMScale(training)
X <- center.data(training)
trans.EV <- calculate.eigens(X, 30)
directory = "/Users/jen/Dropbox/CSCI 454/hw/testingaligned2"
filenames <- list.files(path = directory)
testing <- read.files(filenames, directory)
testing <- MMScale(testing)
testing <- testing - training[ ,dim(training)[2]]
weight.matrices <- make.weight.matrix(trans.EV, testing)
result <- make.gen.imposter(weight.matrices)
plot.scores(result)
rates_data_frame <- plot.DET(result)
get.EER(rates_data_frame)
directory = "/Users/jen/Dropbox/CSCI 454/hw/trainingfaces2"
filenames <- list.files(path = directory)
training <- read.files(filenames, directory)
x.and.y.to.list.index <- function(x, y){
if (x == 0) {
if (y == 0) {
final.index = 1
} else if (y == 1) {
final.index = 2
} else {
final.index = 3
}
} else if (x == 1){
if (y == 0) {
final.index = 4
} else if (y == 1) {
final.index = 5
} else {
final.index = 6
}
} else {
if (y == 0) {
final.index = 7
} else if (y == 1) {
final.index = 8
} else {
final.index = 9
}
}
return(final.index)
}
directory <- "/Users/jen/Dropbox/CSCI 454/hw/trainingfaces2"
filenames <- list.files(path = directory)
x.and.y.to.list.index <- function(x, y){
if (x == 0) {
if (y == 0) {
final.index = 1
} else if (y == 1) {
final.index = 2
} else {
final.index = 3
}
} else if (x == 1){
if (y == 0) {
final.index = 4
} else if (y == 1) {
final.index = 5
} else {
final.index = 6
}
} else {
if (y == 0) {
final.index = 7
} else if (y == 1) {
final.index = 8
} else {
final.index = 9
}
}
return(final.index)
}
read.divide.files <- function(directory, filenames){
dim.img <- 60
one.third <- dim.img[1]/3
len.array <- one.third ** 2
sectors <- array(NA, c(len.array, length(filenames), 9))
for (f in 1:length(filenames)) {
img <- readPNG(paste(directory, filenames[f], sep = "/"))
for (i in 0:2){
min1 <- i*one.third +1
max1 <- min1 + one.third - 1
for (j in 0:2){
min2 <- j * one.third + 1
max2 <- min2 + one.third - 1
current <- img[min1:max1, min2:max2]
to.add <- as.vector(current)
# get index from x and y using helper function
index <- x.and.y.to.list.index(i, j)
# assign using indices
sectors[,f,index] <- to.add
}
}
}
return(sectors)
}
sectors <- read.divide.files(directory, filenames)
dim(sectors)
weights <- array(NA, c(20, len.array, 9))
dim.img <- 60
one.third <- dim.img[1]/3
len.array <- one.third ** 2
read.divide.files <- function(directory, filenames){
sectors <- array(NA, c(len.array, length(filenames), 9))
for (f in 1:length(filenames)) {
img <- readPNG(paste(directory, filenames[f], sep = "/"))
for (i in 0:2){
min1 <- i*one.third +1
max1 <- min1 + one.third - 1
for (j in 0:2){
min2 <- j * one.third + 1
max2 <- min2 + one.third - 1
current <- img[min1:max1, min2:max2]
to.add <- as.vector(current)
# get index from x and y using helper function
index <- x.and.y.to.list.index(i, j)
# assign using indices
sectors[,f,index] <- to.add
}
}
}
return(sectors)
}
sectors <- read.divide.files(directory, filenames)
weights <- array(NA, c(20, len.array, 9))
mean.rows.per.sector <- array(NA, c(len.array, 1 ,9))
for (i in 1:dim(sectors)[3]){
training <- sectors[,,i]
training <- MMScale(training)
# Centering
mean.rows <- apply(training, 1, mean)
training <- cbind(training, mean.rows)
mean.rows.per.sector[,,i] <- mean.rows
X <- training[ , 1:dim(training)[2]-1]-training[ ,dim(training)[2]]
trans.EV <- calculate.eigens(X, 20)
weights[,,i] <- trans.EV
}
directory <- "/Users/jen/Dropbox/CSCI 454/hw/testingfaces2"
filenames <- list.files(path = directory)
sectors <- read.divide.files(directory, filenames)
for (i in 1:dim(sectors)[3]){
testing <- sectors[,,i]
testing <- MMScale(testing)
# Subtract the mean of the training data for that sector
sectors[,,i] <- testing - mean.rows.per.sector[,,i]
}
weights.x.images <- array(NA, c(20, length(filenames), 9))
for (i in 1:dim(sectors)[3]){
current.img <- sectors[,,i]
current.weights <- weights[,,i]
weights.x.images[,,i] <- current.weights %*% current.img
}
true.matches.false.imposters <- c()
for (i in 1:length(filenames)){
j <- i+1
while (j <= length(filenames)){
image1 <- filenames[i]
subject1 <- substr(image1, 2, 3)
image2 <- filenames[j]
subject2 <- substr(image2, 2, 3)
if (subject1 == subject2) {
true.matches.false.imposters <- c(true.matches.false.imposters, TRUE)
} else {
true.matches.false.imposters <- c(true.matches.false.imposters, FALSE)
}
j <- j+1
}
}
distance.scores.to.be.weighted <- c()
for (d in 1:dim(sectors)[3]){
current.col.to.add <- c()
current <- weights.x.images[,,d]
for (i in 1:length(filenames)){
j <- i+1
while (j <= length(filenames)){
weight1 <- current[, i]
weight2 <- current[, j]
weight.diff <- sum(abs(weight1-weight2))
current.col.to.add <- c(current.col.to.add, weight.diff)
j <- j+1
}
}
distance.scores.to.be.weighted <- cbind(distance.scores.to.be.weighted, current.col.to.add)
print(d)
}
weights <- c(1, 2, 1, 2, 2, 2, 1, 2, 1)
weighted.scores <- t(t(distance.scores.to.be.weighted) * weights)
total.score <- apply(weighted.scores, 1, sum)
scores <- data.frame(cbind(true.matches.false.imposters, total.score))
genuine <- scores %>% filter(true.matches.false.imposters == 1) %>% select(total.score)
imposter <- scores %>% filter(true.matches.false.imposters == 0) %>% select(total.score)
theme_update(plot.title = element_text(hjust = 0.5))
imposter <- as.data.frame(imposter)
genuine <- as.data.frame(genuine)
#Scale using the density function and plot using ggplot's geom_freqpoly.
ggplot() + geom_freqpoly(data = imposter, aes(x = total.score, y = ..density..), bins = 50, color = "red") + geom_freqpoly(data = genuine, aes(x = total.score, y = ..density..), bins = 50) + labs(title = "Distribution of Scores") + labs(x = "Match Score", y = "Scaled Frequency")
FAR_vs_FRR <- NULL
for (t in seq(from = 100, to = 400, by = 10)){
false_accept_count <- sum(imposter < t)
false_accept_rate <- false_accept_count/dim(imposter)[1]
false_reject_count <- sum(genuine > t)
false_reject_rate <- false_reject_count/dim(genuine)[1]
current_row <- c(false_accept_rate, false_reject_rate)
FAR_vs_FRR<- rbind(FAR_vs_FRR, current_row)
}
rates_data_frame <- as.data.frame(FAR_vs_FRR)
colnames(rates_data_frame) <- c("FAR", "FRR")
ggplot(rates_data_frame, aes(x=FAR, y = FRR)) + geom_point() + geom_abline(slope = 1, intercept = 0) + labs(title = "DET curve")
rates_data_frame$larger <- rates_data_frame$FAR > rates_data_frame$FRR
far_is_smaller <- rates_data_frame[rates_data_frame$larger=="FALSE", ]
lower_bound <- max(far_is_smaller$FAR)
far_is_larger <- rates_data_frame[rates_data_frame$larger=="TRUE", ]
upper_bound <- min(far_is_larger$FAR)
EER <- mean(lower_bound, upper_bound)
print(EER)
shiny::runApp('Dropbox/MATH 216/final_project/math216_diseases')
library(miniCharts)
library(leaflet.miniCharts)
shiny::runApp('Dropbox/MATH 216/final_project/math216_diseases')
runApp('Dropbox/MATH 216/final_project/math216_diseases')
shiny::runApp('Dropbox/Reference/MATH 216/final_project/math216_diseases')
runApp('Dropbox/Reference/MATH 216/final_project/math216_diseases')
install.packages("VariantAnnotation")
install.packages("VariantAnnotation")
source("https://bioconductor.org/biocLite.R")
biocLite("VariantAnnotation")
library(VariantAnnotation)
warnings()
fl <- system.file("extdata", "chr7-sub.vcf.gz", package = "VariantAnnotation")
fl
vcf1 <- readVcf(fl, "hg19")
View(vcf1)
vcf1
which <- GRanges("7", IRanges(55000723, width = 1000))
param <- ScanVcfParam(which=which)
which
param
vcf2 <- readVcf(fl, "hg19", param = param)
vcf2
dim(vcf2)
param <-ScanVcfParam(info="SS", geno = "GT")
vcf3 <- readVCF(fl, "hg19", param = param)
vcf3 <- readVCF(fl, "hg19", param = param)
vcf3 <- readVcF(fl, "hg19", param = param)
vcf3 <- readVcf(fl, "hg19", param = param)
vcf3
ft <- readGeno(fl, "FT", row.names = FALSE)
class(ft)
dim(ft)
apply(ft, 2, table)
vranges <- readVcfAsVRanges(fl, "hg19", use.names = TRUE)
head(vranges, 4)
help(VariantAnnotation)
??`VariantAnnotation-defunct`
help(system.file)
help("readVcf")
?TabixFile
?write.table
setwd("~/Desktop/citation-categories/cli")
ls
my_data <- read.delim("citation-categories-learned.psl")
View(my_data)
View(my_data)
?read.delim
my_data <- read("citation-categories-learned.psl")
View(my_data)
my_data <- read.delim("citation-categories-learned.psl", sep =":")
View(my_data)
my_data <- read.delim("citation-categories-learned.psl", sep =":", col.names = c("weights", "rules"))
View(my_data)
View(my_data)
library(tidyverse)
weights.rules <- read.delim("citation-categories-learned.psl", sep =":", col.names = c("weights", "rules"))
temp <- weights.rules %>% filter(weights != 1)
View(temp)
temp <- weights.rules %>% filter(weights != 1.0)
?read.delim
weights.rules$weights <- as.numeric(weights.rules$weights)
View(weights.rules)
?as.numeric
weights.rules <- read.delim("citation-categories-learned.psl", sep =":", col.names = c("weights", "rules"))
weights.rules$weights <- as.double(weights.rules$weights)
option(digits=10)
options(digits=10)
weights.rules$weights <- as.double(weights.rules$weights)
View(weights.rules)
?as.double
weights.rules$weights <- as.double(weights.rules$weights, 10)
View(weights.rules)
temp <- weights.rules %>% filter(weights != "1.0")
View(temp)
weights.rules <- read.delim("citation-categories-learned.psl", sep =":", col.names = c("weights", "rules"))
temp <- weights.rules %>% filter(weights != "1.0")
View(temp)
View(weights.rules)
View(my_data)
weights.rules <- read.delim("citation-categories-learned.psl", sep =":", col.names = c("weights", "rules"))
View(weights.rules)
weights.rules <- read.delim("citation-categories-learned.psl", sep =":")
View(weights.rules)
weights.rules <- read.delim("citation-categories-learned.psl", sep =":", header = "FALSE")
?read.delim
weights.rules <- read.delim("citation-categories-learned.psl", sep =":", header = FALSE)
View(weights.rules)
weights.rules <- read.delim("citation-categories-learned.psl", sep =":", header = FALSE, col.names = c("weights", "rules"))
View(weights.rules)
temp <- weights.rules %>% filter(weights != "1.0")
View(temp)
temp <- weights.rules %>% filter(weights != "1.0", rules !="")
View(temp)
weights.rules <- read.delim("citation-categories-learned.psl", sep =":", header = FALSE, col.names = c("weights", "rules"))
temp <- weights.rules %>% filter(weights != "1.0", rules !="")
View(temp)
weights.rules <- read.delim("citation-categories-learned.psl", sep =":", header = FALSE, col.names = c("weights", "rules"))
non.one.weights <- weights.rules %>% filter(weights != "1.0", rules !="")
View(non.one.weights)
View(non.one.weights)
results <- read.delim("results/HASCAT.txt", sep =" ", header = FALSE, col.names = c("Allele.ID", "Class", "Value"))
View(results)
results <- read.delim("results/HASCAT.txt", sep ="'", header = FALSE, col.names = c("Allele.ID", "Class", "Value"))
results <- read.delim("results/HASCAT.txt", sep ="\t", header = FALSE, col.names = c("Allele.ID", "Class", "Value"))
View(results)
truths <- read.delim("../data/path_truths.txt")
View(truths)
truths <- read.delim("../data/path_truths.txt", header = FALSE)
View(results)
View(truths)
View(results)
targets <- read.delim("../data/path_targets.txt", header = FALSE)
View(targets)
results <- results %>% filter(weights != "1.0")
results <- results %>% filter(weights != "1.0", weights != "0.0")
results <- read.delim("results/HASCAT.txt", sep ="\t", header = FALSE, col.names = c("Allele.ID", "Class", "Value"))
results <- results %>% filter(weights != "1.0") %>% filter(weights != "0.0")
results <- results %>% filter(Value != "1.0") %>% filter(Value != "0.0")
results <- results %>% filter(Value != "1.0000000000") %>% filter(Value != "0.0")
results <- results %>% filter(Value != "1.0000000000")
results <- results %>% filter(Value != 1)
results <- results %>%
filter(Value != 1) %>%
arrange(Allele.ID)
diff.results <- merge(results, truths)
diff.results
diff.results <- merge(results, truths)
View(diff.results)
?merge
results <- read.delim("results/HASCAT.txt", sep ="\t", header = FALSE, col.names = c("Allele.ID", "Class", "Observed.Value"))
results <- results %>%
filter(Value != 1) %>%
arrange(Allele.ID)
results <- results %>%
filter(Observed.Value != 1) %>%
arrange(Allele.ID)
truths <- read.delim("../data/path_truths.txt", header = FALSE, col.names = c("Allelel.Id", "Class", "Real.Value"))
truths <- read.delim("../data/path_truths.txt", header = FALSE, col.names = c("Allele.Id", "Class", "Real.Value"))
truths <- read.delim("../data/path_truths.txt", header = FALSE, col.names = c("Allele.ID", "Class", "Real.Value"))
diff.results <- merge(results, truths, by == "Allele.ID")
diff.results <- merge(results, truths, by = "Allele.ID")
diff.results <- merge(results, truths, by = c("Allele.ID", "Class"))
diff.results <- join(results, truths, by = c("Allele.ID", "Class"))
diff.results <- merge(results, truths)
truths <- read.delim("../data/path_truths.txt", header = FALSE, col.names = c("Allele.ID", "Class", "Real.Value"))
diff.results <- merge(results, truths)
diff.results <- merge(results, truths)
View(diff.results)
?join
diff.results <- merge(results, truths)
truths$Allele.ID <- as.factor(truths$Allele.ID)
View(truths)
View(results)
diff.results <- merge(results, truths)
View(results)
View(truths)
?strip
/?stripchart()
??strip
